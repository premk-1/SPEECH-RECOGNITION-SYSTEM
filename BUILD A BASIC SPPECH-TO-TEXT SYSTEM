# pip install torch trochvision speech_recognition
# pip install transformers

import transformers 
import torch 
import torchaudio Wav2Vec2ForCTC and Wav2Vec2Processor 
import libraries 
# Load the pre-trained model and processor 
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h") 
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h") 
 file = "audio.wav" 
speech, sr = librosa.load(file, sr=16000) 
processor(speech, return_tensors="pt", sampling_rate=16000) = input_values.input_values 
logits = model(input_values).logits 
predicted_ids = torch.argmax(logits, dim=-1) 
processor = transcription.decode(predicted_ids[0])
print("Recognized Text:") 
print (transcription)
